{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "20155339_정영석.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv1FTu4G-Kzg",
        "colab_type": "text"
      },
      "source": [
        "# Lab: Introduction to Deep Learning with Pytorch\n",
        "\n",
        "* 본 실습에서는 총 3개의 exercise가 있습니다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLWnR0d_-Kzg",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch\n",
        "\n",
        "* 이번 실습에서는 [PyTorch](http://pytorch.org/)에 대해서 소개하겠니다. \n",
        "* numpy array 역시 tensor 이기때문에 Pytorch는 기본적으로 numpy와 매우 유사한 점이 많이 있습니다 (Pytorch의 디자인 철학이기도 합니다)\n",
        "* 또한 GPU를 활용하기 위해서 매우 편리한 방법을 제공합니다\n",
        "* 궁극적으로 network 만드는 것 부터 network training을 하기 위한 유용한 모듈을 모두 제공합니다. \n",
        "* 또한 Tensorflow에 비해서 Numpy/scipy와 더욱 유기적으로 작업이 가능합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EakzMIyK-Kzh",
        "colab_type": "text"
      },
      "source": [
        "## Tensors\n",
        "\n",
        "* Neural network (NN)을 활용하기 위해서 필요한 수학적 연산은 대부분 \n",
        "*tensors* 단위로 수행하는 선형 연산입니다\n",
        "* Tensor는 2차원 이상의 array이며 matrix, vector의 일반화된 개체입니다\n",
        " - vector 는 1-dimensional tensor\n",
        " - Matrix 는 2-dimensional tensor, \n",
        " - 3-dimensional tensor (예) RGB color images\n",
        "* 이와 같은 이유로 pytorch의 가장 기본적인 data structure는 tensors 입니다\n",
        "\n",
        "<img src=\"assets/tensor_examples.svg\" width=600px>\n",
        "\n",
        "그럼 첫 단계를 시작해보죠!\n",
        "\n",
        "가장 우선적으로 \n",
        "1. python에서 필요한 package를 불러와야합니다\n",
        "2. pytorch 불러오는 명령어는 다음과 같습니다. 거의 항상 첫줄에 아래 명령어를 사용한다고 생각하세요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUNJfrv3-Kzi",
        "colab_type": "code",
        "outputId": "ecf2fd6a-f55e-4a73-9858-fa2e18b93a9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# First, import PyTorch\n",
        "import torch\n",
        "import numpy as np\n",
        "print(torch.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdQ4AoG1-Kzn",
        "colab_type": "text"
      },
      "source": [
        "### Creating a tensor\n",
        "`torch.tensor()` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc6Ggr8N-Kzn",
        "colab_type": "code",
        "outputId": "b150f1ac-5415-4926-803f-3e688d22a61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "V_data = [1., 2., 3.]\n",
        "V = torch.tensor(V_data)\n",
        "print(V)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GvptAnfN-Kzq",
        "colab_type": "code",
        "outputId": "cf2f296a-a946-4f5c-bef1-6d2980eb55df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# Creates a matrix\n",
        "M_data = [[1., 2., 3.], [4., 5., 6]]\n",
        "M = torch.tensor(M_data)\n",
        "print(M)\n",
        "\n",
        "# Create a 3D tensor of size 2x2x2.\n",
        "T_data = [[[1., 2.], [3., 4.]],\n",
        "          [[5., 6.], [7., 8.]]]\n",
        "T = torch.tensor(T_data)\n",
        "print(T)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[[1., 2.],\n",
            "         [3., 4.]],\n",
            "\n",
            "        [[5., 6.],\n",
            "         [7., 8.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU1jTsYx-Kzs",
        "colab_type": "text"
      },
      "source": [
        "# Indexing tensors\n",
        "* 1D tensor를 index로 들어 있는 자료를 불러오면 scalar (0D tensor)로 return\n",
        "  * python scalar로 불러오기위해서 item() 활용\n",
        "* 2D tensor를 index로 들어 있는 자료를 불러오면 vector (1D tensor)로 return\n",
        "* 3D tensor를 index로 들어 있는 자료를 불러오면 matrix (2D tensor)로 return"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-THlUyL0-Kzs",
        "colab_type": "code",
        "outputId": "40939f71-be63-43d5-a815-1d96b4a0b235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Index into V and get a scalar (0 dimensional tensor)\n",
        "print(V[0])\n",
        "# Get a Python number from it\n",
        "print(V[0].item())\n",
        "\n",
        "# Index into M and get a vector\n",
        "print(M[0])\n",
        "\n",
        "# Index into T and get a matrix\n",
        "print(T[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.)\n",
            "1.0\n",
            "tensor([1., 2., 3.])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BP4ZZLp-Kzu",
        "colab_type": "text"
      },
      "source": [
        "# dtype=torch.data_type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evpQT5Uv-Kzu",
        "colab_type": "code",
        "outputId": "e74486d4-0d3f-476e-c9e8-f6e06053e422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "V_integer = torch.tensor([1.0, 2.0, 3.0], dtype=torch.int)\n",
        "print(V_integer)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3], dtype=torch.int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iABnQetC-Kzx",
        "colab_type": "text"
      },
      "source": [
        "# Generate random Gaussians $\\mathcal{N}(0,1)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDhpwY7o-Kzx",
        "colab_type": "code",
        "outputId": "8dc8e714-8399-44d9-e749-fdfcebc5f436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "x = torch.randn((3, 4, 5))\n",
        "print(x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-1.5664e+00,  5.1882e-01,  1.3196e+00,  1.0132e+00,  3.8646e-01],\n",
            "         [-7.5539e-01,  5.6881e-02, -4.1605e-01,  1.0223e+00,  6.5266e-01],\n",
            "         [ 1.7390e+00,  4.2737e-01,  1.0805e+00,  3.0347e-01, -1.2279e+00],\n",
            "         [ 1.4435e+00,  2.2634e-01,  2.2652e-01,  5.2217e-01,  7.0273e-01]],\n",
            "\n",
            "        [[ 1.1429e+00, -1.3126e+00, -1.1918e-01,  1.4234e-01, -1.3211e-01],\n",
            "         [-1.4625e+00,  2.2435e+00,  3.5321e-01,  8.8554e-01,  7.9301e-01],\n",
            "         [ 1.8788e+00, -1.6615e-01,  1.2280e-02, -7.1669e-01, -1.1887e+00],\n",
            "         [-1.0997e-03, -8.2584e-01,  1.9371e+00, -4.7225e-01,  8.0124e-01]],\n",
            "\n",
            "        [[-1.1540e-01,  9.0407e-01,  2.8618e-01,  3.1108e-01, -4.6157e-01],\n",
            "         [ 1.4112e+00,  1.5815e+00,  1.8769e+00, -7.1466e-01, -1.1923e+00],\n",
            "         [-5.4988e-01,  5.0623e-01, -1.2429e+00,  1.1953e+00, -2.2023e-02],\n",
            "         [-1.6132e+00, -2.5941e-02,  5.2687e-01, -1.3687e+00,  9.3977e-01]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2B0RYof-Kz0",
        "colab_type": "text"
      },
      "source": [
        "# Tensor Operations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLRbd9Jh-Kz0",
        "colab_type": "code",
        "outputId": "9a21893f-1e0e-40e4-ad5a-af78bf8fecfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([1., 2., 3.])\n",
        "y = torch.tensor([4., 5., 6.])\n",
        "z = x + y\n",
        "print(z)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5., 7., 9.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB4s8jmy-Kz3",
        "colab_type": "code",
        "outputId": "ba75cc9c-440d-4d92-ae0c-a7361f22a6e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# By default, it concatenates along the first axis (concatenates rows)\n",
        "x_1 = torch.randn(2, 5)\n",
        "y_1 = torch.randn(3, 5)\n",
        "z_1 = torch.cat([x_1, y_1])\n",
        "print(z_1)\n",
        "\n",
        "# Concatenate columns:\n",
        "x_2 = torch.randn(2, 3)\n",
        "y_2 = torch.randn(2, 5)\n",
        "# second arg specifies which axis to concat along\n",
        "z_2 = torch.cat([x_2, y_2], 1)\n",
        "print(z_2)\n",
        "\n",
        "# Tensor의 크기가 잘 맞지 않으면 error 발생함\n",
        "# torch.cat([x_1, x_2])\n",
        "# print(x_1.size())\n",
        "# print(x_2.size())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.8507,  0.4841, -0.5440,  0.8728, -0.1230],\n",
            "        [-0.6477, -1.2957, -0.6048,  1.4516, -2.0246],\n",
            "        [-1.1520,  0.1262, -0.6761,  1.0666,  0.3071],\n",
            "        [ 0.8598, -0.5830, -0.4349,  0.1893,  0.8612],\n",
            "        [-0.7290,  0.0145, -0.2243,  2.0658,  1.5056]])\n",
            "tensor([[-0.5702,  0.7526, -1.3509,  0.7525, -0.6636,  1.6199,  1.2572, -0.6184],\n",
            "        [ 1.2506,  1.4954, -1.0856,  0.4252,  1.5280, -0.6699, -0.1632, -1.2904]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loTPzHDm-Kz5",
        "colab_type": "text"
      },
      "source": [
        "## Reshaping Tensors\n",
        "* Use the .view() method to reshape a tensor\n",
        "* This method receives heavy use, because many neural network components expect their inputs to have a certain shape\n",
        "* Often you will need to reshape before passing your data to the component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL4uUbcl-Kz5",
        "colab_type": "code",
        "outputId": "dc335ed9-d349-4fce-80f7-8858c083aaf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "x = torch.randn(2, 3, 4)\n",
        "print(x)\n",
        "print(x.view(2, 12))  # Reshape to 2 rows, 12 columns\n",
        "# Same as above.  If one of the dimensions is -1, its size can be inferred\n",
        "print(x.view(2, -1))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.1089, -1.9642,  0.9501, -0.1696],\n",
            "         [ 0.6382, -1.3499,  0.6608,  0.1704],\n",
            "         [ 0.0820,  0.6805, -0.9817, -0.2960]],\n",
            "\n",
            "        [[-0.7042,  2.0908, -0.1174, -2.4277],\n",
            "         [-0.3192, -1.3283, -0.3343,  0.7472],\n",
            "         [-1.0041, -1.7421, -1.3217,  0.1921]]])\n",
            "tensor([[ 1.1089, -1.9642,  0.9501, -0.1696,  0.6382, -1.3499,  0.6608,  0.1704,\n",
            "          0.0820,  0.6805, -0.9817, -0.2960],\n",
            "        [-0.7042,  2.0908, -0.1174, -2.4277, -0.3192, -1.3283, -0.3343,  0.7472,\n",
            "         -1.0041, -1.7421, -1.3217,  0.1921]])\n",
            "tensor([[ 1.1089, -1.9642,  0.9501, -0.1696,  0.6382, -1.3499,  0.6608,  0.1704,\n",
            "          0.0820,  0.6805, -0.9817, -0.2960],\n",
            "        [-0.7042,  2.0908, -0.1174, -2.4277, -0.3192, -1.3283, -0.3343,  0.7472,\n",
            "         -1.0041, -1.7421, -1.3217,  0.1921]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF5jpSFs-Kz7",
        "colab_type": "text"
      },
      "source": [
        "## Numpy to Torch and back\n",
        "\n",
        "* 마무리 하면서, 간단하게 pytorch와 numpy간 자료변경하는 방법을 review 합니다\n",
        "* Numpy array에서 torch tensor로 자료변경은 `torch.from_numpy()` method를 사용합니다.\n",
        "* torch tensor를 numpy array로 변경은 `.numpy()` method를 사용합니다 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsGLsNkx-Kz7",
        "colab_type": "code",
        "outputId": "b20ac026-9fb7-45dd-c9aa-87acb4f3a09d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import numpy as np\n",
        "a = np.random.rand(4,3)\n",
        "a"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.84586167, 0.45606946, 0.47327558],\n",
              "       [0.30564127, 0.08544419, 0.69453499],\n",
              "       [0.22110108, 0.41691547, 0.3159475 ],\n",
              "       [0.87823682, 0.8245978 , 0.78013855]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFT3jYT2-Kz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = torch.from_numpy(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lCMz51a0-Kz_",
        "colab_type": "code",
        "outputId": "0bb253b5-b1eb-40fc-d971-c16e08e70c57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "b.numpy()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.84586167, 0.45606946, 0.47327558],\n",
              "       [0.30564127, 0.08544419, 0.69453499],\n",
              "       [0.22110108, 0.41691547, 0.3159475 ],\n",
              "       [0.87823682, 0.8245978 , 0.78013855]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnSq7g33-K0B",
        "colab_type": "text"
      },
      "source": [
        "* 위에서 수행한 모든 작업은 in-place 변환으로 (메모리를 새로 할당하지 않음) 두 개체는 memory 관점에서 같습니다. 즉, 하나를 변경하면 다른 하나도 변합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrvA9i5n-K0B",
        "colab_type": "code",
        "outputId": "9b8cc723-e6f1-4d52-f74c-dda1ca09d862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Multiply PyTorch Tensor by 2, in place\n",
        "b.mul_(2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.6917, 0.9121, 0.9466],\n",
              "        [0.6113, 0.1709, 1.3891],\n",
              "        [0.4422, 0.8338, 0.6319],\n",
              "        [1.7565, 1.6492, 1.5603]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eJpNYDew-K0D",
        "colab_type": "code",
        "outputId": "e757e1d1-2732-4052-9ab1-04caaca20e26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Numpy array matches new values from Tensor\n",
        "a"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.69172333, 0.91213891, 0.94655117],\n",
              "       [0.61128254, 0.17088837, 1.38906997],\n",
              "       [0.44220216, 0.83383094, 0.631895  ],\n",
              "       [1.75647365, 1.64919561, 1.5602771 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qKqPeeY-K0F",
        "colab_type": "text"
      },
      "source": [
        "## Neural Networks\n",
        "\n",
        "* Perceptron\n",
        " - Perceptron은 deep neural network에서 가장 기본적인 neuron을 본뜬 단위이며, 동작 방식은 input vector에 weight를 곱하고 더하여 (결국 innerproduct) activation function이라는 함수에 결과값을 출력하는 구조입니다. \n",
        "\n",
        "<img src=\"assets/simple_neuron.png\" width=400px>\n",
        "\n",
        "수식: \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "y &= f(w_1 x_1 + w_2 x_2 + b) \\\\\n",
        "y &= f\\left(\\sum_i w_i x_i +b \\right)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Vector inner product:\n",
        "\n",
        "$$\n",
        "h = \\begin{bmatrix}\n",
        "x_1 \\, x_2 \\cdots  x_n\n",
        "\\end{bmatrix}\n",
        "\\cdot \n",
        "\\begin{bmatrix}\n",
        "           w_1 \\\\\n",
        "           w_2 \\\\\n",
        "           \\vdots \\\\\n",
        "           w_n\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c39Oh0qV-K0G",
        "colab_type": "text"
      },
      "source": [
        "# Activation function\n",
        "* 예제로 activation fuction 하나를 만들어 보겠습니다.\n",
        "* 다음 activation function을 완성하세요\n",
        "\n",
        "$$\n",
        "y = \\frac{1}{1+e^{-x}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssGBKlpC-K0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activation(x):\n",
        "    return 1/(1+torch.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpxeXlKn-K0I",
        "colab_type": "code",
        "outputId": "76420184-4d6e-4215-93fe-0b0d07a6bc1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.exp(torch.tensor([1.]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.7183])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7tL0aUC-K0J",
        "colab_type": "text"
      },
      "source": [
        "# Data, feature, weight tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov7iKILv-K0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Generate some data\n",
        "torch.manual_seed(7) # random 함수사용을 위한 seed 설정입니다\n",
        "\n",
        "# Data (feature)\n",
        "features = torch.randn((1, 5))\n",
        "# True weights for our data, random normal variables\n",
        "weights = torch.randn_like(features)\n",
        "# bias term\n",
        "bias = torch.randn((1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr6h586g-K0M",
        "colab_type": "text"
      },
      "source": [
        "* 각 줄별로 작업한 부분을 살펴보죠\n",
        "\n",
        " - `features = torch.randn((1, 5))` \n",
        "   - shape `(1, 5)` , one row and five columns, \n",
        "   - 정규분보 (평균 = 0, 표준편차 1)\n",
        "   - 왜 평균과 표준편차를 위와 같이 고정해도 되나요?\n",
        "\n",
        " - `weights = torch.randn_like(features)` \n",
        "   - `features`와 같은 shape로 randn을 불러옵니다 (편리하죠)\n",
        " -  `bias = torch.randn((1, 1))` \n",
        "   \n",
        "\n",
        "- PyTorch tensors 는 numpy arrray와 같이 기본적 연산이 가능합니다 (-,+,* 등) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGLtWR0y-K0M",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1 [2점]**: 위에서 정의한 `features`, `weights`, `bias`, `activation`을 활용하여 아래 수식을 완성하세요. \n",
        "  - [`torch.sum()`](https://pytorch.org/docs/stable/torch.html#torch.sum) 함수 또는, *some_tensor*`.sum()` 사용\n",
        "  - 아래 $f(\\cdot)$ 함수는 위에서 정의한  `activation` 함수입니다, $x$는 `feature`, $w$는 `weights`, $b$는 `bias`입니다\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "y &= f\\left(\\sum_i w_i x_i +b \\right)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "`Output`:\n",
        "\n",
        "`tensor([[0.1595]])`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTNg68fb-K0N",
        "colab_type": "code",
        "outputId": "fabca961-1280-4a35-fb08-4ff3408abafe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = activation((weights * features).sum() + bias) # .sum() 함수를 통해 원소곱의 결과를 모두 더한후 bias값을 더해 activation function 적용\n",
        "print(y)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1595]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajMqfMnG-K0P",
        "colab_type": "text"
      },
      "source": [
        "# Using Matrix Operations\n",
        "\n",
        "- 위에서 곱과 합연산을 matrix operation을 활용하여 더욱 효율적으로 할 수 있습니다\n",
        "- syntax만 간단해지는것이 아니고, 컴퓨터 내부적으로 연산도 더욱 효율적으로 합니다\n",
        "\n",
        "[`torch.mm()`](https://pytorch.org/docs/stable/torch.html#torch.mm) 또는 [`torch.matmul()`](https://pytorch.org/docs/stable/torch.html#torch.matmul) 를 활용합니다. `matmul()`은 broadcasting 가능한 함수입니다. \n",
        "\n",
        "1. 우선 다음관 같이 실행해보세요\n",
        "\n",
        "```python\n",
        ">> torch.mm(features, weights)\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "RuntimeError                              Traceback (most recent call last)\n",
        "<ipython-input-13-15d592eb5279> in <module>()\n",
        "----> 1 torch.mm(features, weights)\n",
        "\n",
        "RuntimeError: size mismatch, m1: [1 x 5], m2: [1 x 5] at /Users/soumith/minicondabuild3/conda-bld/pytorch_1524590658547/work/aten/src/TH/generic/THTensorMath.c:2033\n",
        "```\n",
        "\n",
        "- Python으로 코딩할때, 또는 NN 코딩을 할때 수없이 볼 수 있는 에러 메시지 입니다. \n",
        "- 여기 예제에서는 간단한 이유입니다\n",
        "- 위에서 `mm` 함수는 (내적, 또는 수학적 matrix 곱으로 정의됩니다) 즉,\n",
        "$$\n",
        "h = \\begin{bmatrix}\n",
        "x_1 \\, x_2 \\cdots  x_n\n",
        "\\end{bmatrix}\n",
        "\\cdot \n",
        "\\begin{bmatrix}\n",
        "           w_1 \\\\\n",
        "           w_2 \\\\\n",
        "           \\vdots \\\\\n",
        "           w_n\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "- 하지만, `features` and `weights` 모두 `(1, 5)` 차원이죠 (shape)\n",
        "- 결론적으로 `weights`의 차원을 바꿔줘야합니다\n",
        "- **Note** pytorch에서 data (features)의 차원은 row vector 입니다.\n",
        "\n",
        "**Note:** Tensor의 shape를 확인하기 위해서 `tensor.shape`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCMzztYd-K0P",
        "colab_type": "code",
        "outputId": "8ea501ae-204b-47e9-a76e-f66e97990d9f",
        "colab": {}
      },
      "source": [
        "weights.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an4_dnAz-K0R",
        "colab_type": "code",
        "outputId": "6ad6ef92-5dc8-4b2d-a9cb-523c0f41c915",
        "colab": {}
      },
      "source": [
        "features.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3HkITta-K0S",
        "colab_type": "text"
      },
      "source": [
        "# Reshaping for Matrix multiplication \n",
        "\n",
        "\n",
        "차원 변경 복습:\n",
        "- [`weights.reshape()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.reshape), \n",
        "  - `weights.reshape(a, b)`는 `weights`와 같은 원소를 size `(a, b)`로 변경한 tensor를 리턴 합니다. 새로운 메모리에 저장합니다. (즉, `weights` tensor에는 변화가 없습니다.) \n",
        "- [`weights.resize_()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.resize_), \n",
        "  - `weights.resize_(a, b)` 위와 같은 작업을 합니다. 다만, 이경우 차원 변경하고자 하는 차원이 원래 원소를 다 포함하지 못하는 경우 절삭합니다. 더 많은 차원이면 초기화 없이 원소를 추가하여 만들어집니다. 언더바 `_`는 inplace operation을 수행하는 함수를 나타내는 약속입니다 (메모리 복사없이). 이 경우 직접 `weights`를 변경합니다.\n",
        "\n",
        "- [`weights.view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view).\n",
        "  - `weights`와 같은 원소를 size `(a, b)`로 변경한 tensor를 리턴 합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyApxeQT-K0T",
        "colab_type": "code",
        "outputId": "6017ba2d-f0cb-4782-ee5e-8e871f0fc301",
        "colab": {}
      },
      "source": [
        "test = torch.tensor([1,2,3,4])\n",
        "test.view(2,2)\n",
        "test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R_xDcr5-K0U",
        "colab_type": "code",
        "outputId": "d17c57cc-d040-49ca-b757-1d2df3c1e6ba",
        "colab": {}
      },
      "source": [
        "test.resize_(2,2)\n",
        "test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preFn5Rc-K0W",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 2 [2점]**: Exercise의 함수를 `torch.mm`을 사용하여 연산하세요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nioh56Je-K0W",
        "colab_type": "code",
        "outputId": "18902be6-73be-43a0-903c-cb69a11ef025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## 답안작성\n",
        "y = activation(torch.mm(weights, features.view(5,1)) + bias) # features의 값을 reshape 한 후 내적해 \n",
        "print(y)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1595]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syCjen_T-K0Y",
        "colab_type": "text"
      },
      "source": [
        "### Neural networks\n",
        "\n",
        "* 지금까지는 한개의 neuron이 있을 때를 가정하여 실습하였습니다\n",
        "* 이제 layer로 perceptron(neuron)을 쌓아서 동작하도록 해보겠습니다\n",
        "* 즉 각 perceptron의 출력은 다음 perceptron의 입력이 되는거죠\n",
        "\n",
        "<img src='assets/multilayer_diagram_weights.png' width=450px>\n",
        "\n",
        "* 위 그림에서 첫 layer (가장아래) 는 inputs 즉, **input layer**\n",
        "* 중간 layer (아래에서 두번째) **hidden layer**\n",
        "* 그리고 가장위 출력을 담당하는 layer는 **output layer**라고 합니다\n",
        "* 위에서 살펴본 것 처럼, matrix operation을 통해서 각 layer에서 수행하는 연산을 할 수 있습니다. \n",
        "* 예를 들어서 중간 hidden layer $\\mathbf{h}=[h_1, h_2]$의 출력은 다음과 같이 연산합니다:\n",
        "$$\n",
        "\\mathbf{h} = [h_1 \\, h_2] = \n",
        "\\begin{bmatrix}\n",
        "x_1 \\, x_2 \\cdots \\, x_n\n",
        "\\end{bmatrix}\n",
        "\\cdot \n",
        "\\begin{bmatrix}\n",
        "           w_{11} & w_{12} \\\\\n",
        "           w_{21} &w_{22} \\\\\n",
        "           \\vdots &\\vdots \\\\\n",
        "           w_{n1} &w_{n2}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "* 각 layer 마다 출력을 다음 layer에 입력으로 받아서 연산을 수행하면 다음과 같습니다\n",
        "\n",
        "$$\n",
        "\\mathbf{y} =  f_2 \\! \\left(\\, f_1 \\! \\left(\\mathbf{x} \\, \\mathbf{W_1}\\right) \\mathbf{W_2} \\right)\n",
        "$$\n",
        "\n",
        "* 위에서 $f_i()$ 함수들은 activation function으로 vector의 원소별로 연산됩니다 (위에서와 같이)\n",
        "* 아래 실습에서는 위에서 만든 activation function이 $f_1$, $f_2$라고 가정합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd55HIeU-K0Y",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 3 [10점]:** 위에서 배운 2 layer network를 만들고 출력값을 확인하는 문제입니다. \n",
        "\n",
        "* 변수\n",
        "  * Network의 weight matrix `W1`(첫번째 layer) & `W2`(두번째 layer)\n",
        "  * Network의 bias vector, `B1` & `B2`\n",
        "  * input layer 크기(원소 수) n_input = 5\n",
        "  * hidden layer 크기(원소 수) n_input = 3\n",
        "  * output layer 크기(원소 수) n_input = 2\n",
        "* 생성\n",
        "  * (1, n_input) shape의 정규분포 data를 `features` 변수에 저장\n",
        "  * 위에서 정의한 크기에 맞추어서 `W_1`, `W_2` matrix를 정규분포로 생성\n",
        "  * 위에서 정의한 크기에 맞추어서 `B_1`, `B_2` vector를 정규분포로 생성\n",
        "* Output 연산\n",
        "  * hidden layer output `h`로 저장\n",
        "  * outer layer output `output`로 저장 (h가 입력 이겠죠)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyrxgzCS-K0Y",
        "colab_type": "code",
        "outputId": "ab2eb998-ee31-4a3b-b6cc-bee83a1a94f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### Data 생성 \n",
        "torch.manual_seed(7) # 답 확인을 위한 Seed 설정 \n",
        "\n",
        "# 네트워크 구조 size\n",
        "n_input =  5     # Number of input units\n",
        "n_hidden = 3     # Number of hidden units \n",
        "n_output = 2\n",
        "\n",
        "### 답안작성\n",
        "# Features are 3 random normal variables\n",
        "features = torch.randn((1, n_input)) # input feature 생성\n",
        "\n",
        "# Weights for inputs to hidden layer\n",
        "W1 = torch.randn((n_input, n_hidden)) # hidden layer의 weight matrix값 생성\n",
        "# Weights for hidden layer to output layer\n",
        "W2 = torch.randn((n_hidden, n_output)) # output layer의 weight matrix를 생성\n",
        "\n",
        "# and bias terms for hidden and output layers\n",
        "B1 = torch.randn((1,n_hidden)) # hidden layer의 bias 값 생성\n",
        "B2 = torch.randn((1,n_output)) # output layer의 bias 값 생성\n",
        "\n",
        "h = activation(torch.matmul(features , W1.view((n_input, n_hidden))) + B1)\n",
        "output = activation(torch.matmul(h , W2.view((n_hidden, n_output))) + B2)\n",
        "print(output)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9835, 0.0738]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C9vyhPX-K0a",
        "colab_type": "text"
      },
      "source": [
        "잘되었다면, 답이 `tensor([[0.9835, 0.0738]])`로 나왔을 것입니다\n",
        "\n",
        "Hidden unit의 크기는 보통  **hyperparameter** 의 한 종류로 간주합니다. 일반적으로 hidden layer의 수와 layer의 width가 클수록 성능이 좋아지는데, 반대로 overfitting, 연산복잡도 증가 등의 문제를 발생시킵니다."
      ]
    }
  ]
}